amp_level: '02'
batch_size: 10
data_root: /data/libri/
data_test:
- test-clean
data_train:
- train-clean-100
- train-clean-360
- train-other-500
dropout: 0.1
early_stop_metric: wer
early_stop_patience: 3
epochs: 100
experiment_name: DeepSpeech
learning_rate: 0.0005
logs_path: runs/
n_class: 29
n_cnn_layers: 3
n_feats: 128
n_rnn_layers: 5
num_workers: 4
precision: 32
resume_from_checkpoint: null
rnn_dim: 512
stride: 2
